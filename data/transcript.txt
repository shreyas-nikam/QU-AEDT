Hello! Today we will be talking about Understanding the Amendments and Changes to the Proposed Rules.

Let's delve into the amendments and changes to the proposed rules. We'll start with an overview of the topic. The New York City Department of Consumer and Worker Protection has adopted a final rule, amending Title 6 of the Rules of the City of New York. This rule was initially proposed in September 2022, underwent a public hearing, and received comments. A second version was proposed in December 2022, followed by another public hearing and comments.

Now, let's take a brief look at the history of these proposed rules. The Department is adding rules to implement new legislation regarding automated employment decision tools, or AEDTs. These tools are prohibited unless they have been subject to a bias audit within one year of use, information about the bias audit is publicly available, and certain notices have been provided to employees or job candidates. The rules clarify obligations of employers and employment agencies under the new law.

The importance of understanding these amendments and changes cannot be overstated. The rules define terms, clarify requirements for a bias audit, the published results of the required bias audit, and the notices that employers and employment agencies must provide to employees and candidates for employment. They also clarify other obligations for the employer or employment agency.

The Department initially proposed a version of these rules in September 2022. After receiving comments from the public, including employers, employment agencies, law firms, AEDT developers, and advocacy organizations, a second version of the proposed rules was published in December 2022. The changes included modifications to the definition of AEDT, clarifications on the role of an independent auditor, revisions to the required calculations, and more.

The Department received comments about the second version of the proposed rule from the public, leading to further changes in the final rules. These changes include modifying the definition of machine learning, statistical modeling, data analytics, or artificial intelligence to expand its scope, adding a requirement that the bias audit indicate the number of individuals the AEDT assessed that are not included in the calculations because they fall within an unknown category, and more.

Understanding these amendments and changes is crucial for all stakeholders, including employers, employment agencies, law firms, AEDT developers, and advocacy organizations. It ensures compliance with the law and promotes fair and unbiased employment practices.

As we delve deeper into the amendments and changes to the proposed rules, it's crucial to understand the new rules in their entirety. These rules are not just about defining terms, but they also lay out the requirements for a bias audit, the requirements for the published results of the required bias audit, the requirements for notices that employers and employment agencies must provide to employees and candidates for employment, and other obligations for the employer or employment agency.

These rules were born out of the New York City Department of Consumer and Worker Protection's initiative to implement new legislation regarding automated employment decision tools, or AEDTs. The law mandates that these tools must undergo a bias audit within one year of their use, and the information about the bias audit must be publicly available. Additionally, certain notices must be provided to employees or job candidates.

The rules specify that a bias audit of an AEDT must calculate the selection rate for each race/ethnicity and sex category that is required to be reported on to the U.S. Equal Employment Opportunity Commission. These calculations are consistent with Section 1607.4 of the EEOC Uniform Guidelines on Employee Selection Procedures.

The new rules have undergone several iterations, with the Department receiving comments from the public, including employers, employment agencies, law firms, AEDT developers, and advocacy organizations. These comments led to a second version of the proposed rules, which included modifications to the definition of AEDT, clarifications on the role of an independent auditor, revisions to the required calculations, and more.

The final rules include changes such as expanding the definition of machine learning, statistical modeling, data analytics, or artificial intelligence, adding a requirement that the bias audit indicate the number of individuals the AEDT assessed that are not included in the calculations because they fall within an unknown category, and allowing an independent auditor to exclude a category that comprises less than 2% of the data being used for the bias audit from the calculations of impact ratio, among others.

In conclusion, these new rules aim to ensure fairness and transparency in the use of automated employment decision tools, and it's crucial for all stakeholders to understand and adhere to them.

Let's delve into the initial proposal and the public response to the proposed rules. The initial proposal of these rules was made in September 2022. This proposal was put forth by the New York City Department of Consumer and Worker Protection, with the aim of implementing new legislation regarding automated employment decision tools, or AEDTs. These tools are used by employers and employment agencies, and the legislation requires that these tools undergo a bias audit within one year of their use. 

The public was given the opportunity to comment on this initial proposal, and a public hearing was held in November 2022. The feedback received was diverse, coming from employers, employment agencies, law firms, AEDT developers, and advocacy organizations. This feedback was taken into account, leading to the publication of a second version of the proposed rules in December 2022. 

The changes made in this second version were based on the public feedback received. These changes included modifications to the definition of AEDT for greater focus, clarifications on the role of an independent auditor, revisions to the required calculations where an AEDT scores candidates, and clarifications on the types of data that may be used to conduct a bias audit, among others. 

This process of public feedback and revision is a testament to the democratic process at work, where the voices of the public are heard and taken into account in the creation of rules and regulations that affect them. It's a clear example of how public participation can lead to more comprehensive and effective rules.

Let's delve into the final rules and changes that have been made to the proposed rules. These rules were adopted by the New York City Department of Consumer and Worker Protection, or DCWP, to regulate the use of automated employment decision tools, or AEDTs, by employers and employment agencies. 

The first point we need to understand is the definition of "machine learning, statistical modeling, data analytics, or artificial intelligence". These terms have been expanded in scope to cover a wider range of technologies used in AEDTs. 

Next, we'll look at the requirements for a bias audit. A bias audit is a process that checks if an AEDT is biased towards or against certain groups. The rules now require that the bias audit indicate the number of individuals the AEDT assessed that are not included in the calculations because they fall within an unknown category. This number must be included in the summary of results. 

Let's consider some examples of a bias audit. For instance, an independent auditor may exclude a category that comprises less than 2% of the data being used for the bias audit from the calculations of impact ratio. 

Now, when can an employer or employment agency rely on a bias audit conducted using the historical data of other employers or employment agencies? The rules clarify that multiple employers using the same AEDT may rely on the same bias audit so long as they provide historical data, if available, for the independent auditor to consider in such bias audit. 

Let's look at some examples of when an employer or employment agency may rely on a bias audit conducted with historical data, test data, or historical data from other employers and employment agencies. For instance, if an employer uses an AEDT that has been audited using historical data from a similar industry, they may rely on this audit. 

These rules and changes are part of a broader effort to ensure fairness and transparency in the use of AEDTs in employment decisions. They aim to prevent bias and discrimination, and to ensure that all job candidates are evaluated fairly and objectively.

As we delve deeper into the amendments and changes to the proposed rules, let's focus on the detailed definitions and requirements. These are crucial to understanding the rules and their implications. 

Firstly, we have detailed definitions of terms used in the rules. This is important because it ensures that everyone has a clear understanding of what is being discussed. For instance, the term 'Automated Employment Decision Tool' or 'AEDT' is defined in the context of these rules. It refers to a tool used by employers and employment agencies to make decisions about hiring, promoting, or other employment-related decisions. 

Secondly, we have detailed requirements for bias audits, notices to candidates and employees, and other obligations. These requirements are designed to ensure fairness and transparency in the use of automated employment decision tools. For example, a bias audit of an AEDT must calculate the selection rate for each race/ethnicity and sex category, and compare the selection rates to the most selected category to determine an impact ratio. This is consistent with Section 1607.4 of the EEOC Uniform Guidelines on Employee Selection Procedures. 

Furthermore, employers and employment agencies are required to provide certain notices to employees or job candidates. These notices must include information about the bias audit and its results, and instructions for how an individual can request an alternative selection process or a reasonable accommodation under other laws, if available. 

These detailed definitions and requirements are part of the amendments to the rules proposed by the New York City Department of Consumer and Worker Protection. These amendments were made after a public hearing and receiving comments from the public, including employers, employment agencies, law firms, AEDT developers, and advocacy organizations. 

In conclusion, these detailed definitions and requirements are designed to ensure that automated employment decision tools are used in a fair and transparent manner, and that employees and job candidates are informed about their rights and the processes involved.

As we draw towards the conclusion of our discussion, let's take a moment to recap the amendments and changes to the proposed rules. These changes were made in response to public comments and feedback, and they have significant implications for employment and employment agencies. 

The New York City Department of Consumer and Worker Protection, or DCWP, has been instrumental in these changes. They have amended Title 6 of the Rules of the City of New York, focusing on the use of automated employment decision tools, or AEDTs. These tools are now required to undergo a bias audit within one year of their use, and the information about this audit must be publicly available. 

The amendments have clarified the requirements for a bias audit, the published results of the required bias audit, and the notices that employers and employment agencies must provide to employees and candidates for employment. They have also clarified other obligations for the employer or employment agency. 

The changes to the proposed rules have been made in two stages. The first version of the rules was proposed in September 2022, and after receiving public comments, a second version was proposed in December 2022. The final rules reflect the changes made in response to the comments received on the second version. 

These changes include modifications to the definition of AEDT, clarifications on the role of an independent auditor, revisions to the required calculations, and clarifications on the types of data that may be used to conduct a bias audit. 

The final rules also include changes such as expanding the definition of machine learning, statistical modeling, data analytics, or artificial intelligence, adding a requirement for the bias audit to indicate the number of individuals assessed that are not included in the calculations, and allowing an independent auditor to exclude a category that comprises less than 2% of the data being used for the bias audit. 

These amendments and changes to the proposed rules are crucial in the context of employment and employment agencies. They aim to ensure fairness and transparency in the use of automated employment decision tools, and they clarify the obligations of employers and employment agencies. 

As we wrap up, let's reflect on the course content. We've delved into the intricacies of the amendments and changes to the proposed rules, and we've explored their implications for employment and employment agencies. It's my hope that this knowledge will serve you well in your professional endeavors.

Thank you for watching! Do checkout QuantUniversity for more courses.